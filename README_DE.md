# Die zweite Testrunde

[English](./README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README_ZH.md)

## üéØ Ziel

Nachdem der Engpass aus der ersten Testrunde (blockierender RestTemplate-Aufruf im Gateway) behoben wurde, sollte die
neue Durchsatzleistung des Gesamtsystems √ºber das Gateway √ºberpr√ºft werden.
Das Ziel dieser Runde war:

- **die Wirkung** der Umstellung auf WebClient zu **messen**
- m√∂gliche **weitere Engp√§sse** zu identifizieren
- eine neue Leistungsbasis f√ºr sp√§tere Optimierungen zu schaffen

## Durchsatztest nach der Behebung

Nach der Umstellung auf WebClient wurde erneut ein f√ºnfmin√ºtiger Durchsatztest √ºber das Gateway durchgef√ºhrt:

```shell
wrk -t5 -c10 -d300s --timeout=10s --latency http://127.0.0.1:38071/service/hello
```

**Ergebnis**:

> Requests/sec: 4091.91

Originales Protokoll:

```shell
Running 5m test @ http://127.0.0.1:38071/service/hello
  5 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.47ms  772.41us  43.05ms   96.34%
    Req/Sec   822.41     55.76     0.92k    86.56%
  Latency Distribution
     50%    2.36ms
     75%    2.54ms
     90%    2.80ms
     99%    4.65ms
  1227963 requests in 5.00m, 149.90MB read
Requests/sec:   4091.91
Transfer/sec:    511.49KB
```

### Interpretation

- Der Durchsatz stieg von **~1.800 RPS** (vor der Behebung) auf **~4.091 RPS**.
- Das entspricht einer Steigerung um **√ºber 125 %**.
- Die Latenzwerte haben sich ebenfalls **deutlich verbessert**.

Trotz der Verbesserung war der erwartete Wert (deutlich n√§her an der Baseline von ~13.000 RPS) noch nicht erreicht.
Daher war eine weitere Analyse notwendig, um den neuen Engpass zu finden.

## Vertiefte Analyse

Wie in der ersten Runde wurde erneut ein Profiling mit
[JProfiler](https://www.ej-technologies.com/jprofiler) durchgef√ºhrt.

Ein Snapshot der CPU-Zeitverteilung zeigte deutlich, dass **ein gro√üer Teil der Ausf√ºhrungszeit in der Logausgabe**
verbracht wurde:

![cpu-views-call-tree](https://raw.githubusercontent.com/ksewen/Bilder/main/202308161502704.png "CPU Views - Call Tree")

### Warum entsteht dieser Engpass?

Logback schreibt Logs **standardm√§√üig synchron**, d. h. der arbeitende Thread muss warten, bis der Logeintrag verarbeitet ist.   

Bei hoher Last k√∂nnte dies dazu f√ºhren:
- Blockierungen auf der kritischen Ausf√ºhrungspfad
- unn√∂tigen I/O-Wartezeiten
- Verlangsamung der Event-Loop
- sinkender Gesamt-Durchsatzleistung

Damit wurde klar:
**Nach der Behebung des ersten Engpasses war die synchrone Logausgabe der n√§chste dominierende Leistungsfaktor.**

## Behebung

Logback bietet einen [AsyncAppender](https://logback.qos.ch/manual/appenders.html#AsyncAppender),
mit dem die Logausgabe in Hintergrund-Threads ausgelagert wird.

Vorteile des AsyncAppender:
- **entlastet** den ausf√ºhrenden Thread
- Logvorg√§nge werden **asynchron verarbeitet**
- **weniger Blockierungen** im kritischen Request-Flow
- bessere Skalierbarkeit bei hoher Last

Ein typisches Beispiel:

```xml
<appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
    <appender-ref ref="FILE"/>
</appender>
```

Damit wandert das Schreiben der Logs aus der Hauptlogik heraus, und die Anfrageverarbeitung w√ºrde sp√ºrbar beschleunigt.

## Erwartetes Ergebnis

Nach der Aktivierung des AsyncAppender k√∂nnte:
- die Latenz weiter **sinken**
- der Durchsatz weiter **steigen**
- die Blockierungszeit im Gateway deutlich **geringer** werden

Die tats√§chliche Wirkung wird in der [**n√§chsten Testrunde**](https://github.com/ksewen/gateway-bottleneck-lab/tree/0.0.3?tab=readme-ov-file) √ºberpr√ºft.

## üü© Gesamtfazit

- Die erste Korrektur (WebClient) war erfolgreich: **Durchsatz +125 %**.
- Mittels JProfiler wurde die **synchrone Logausgabe** als neuer Engpass identifiziert.
- Logback‚Äôs **AsyncAppender** bietet eine gezielte, m√∂gliche L√∂sung, dessen Wirkung in der folgenden Testrunde √ºberpr√ºft wird.
